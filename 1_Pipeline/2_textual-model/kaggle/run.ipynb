{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "import cpuinfo\n",
    "\n",
    "# Experiment Tracking\n",
    "import wandb\n",
    "\n",
    "# Sklearn Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support, \n",
    "    matthews_corrcoef, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Hugging Face Datasets\n",
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# PEFT (Parameter Efficient Fine-Tuning)\n",
    "from peft import (\n",
    "    LoraConfig, \n",
    "    get_peft_model, \n",
    "    TaskType,\n",
    "    PeftModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19728a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"wandb_api\")\n",
    "    wandb.login(key=api_key)\n",
    "    anony = None\n",
    "except:\n",
    "    anony = \"must\"\n",
    "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae78701",
   "metadata": {},
   "source": [
    "# GPU & CPU Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CPU model and cores\n",
    "cpu_info = cpuinfo.get_cpu_info()\n",
    "print(f\"CPU Model: {cpu_info['brand_raw']}\")\n",
    "print(f\"Cores: {psutil.cpu_count(logical=False)} Physical / {psutil.cpu_count(logical=True)} Logical\")\n",
    "\n",
    "# Get clock speed\n",
    "print(f\"Max Frequency: {psutil.cpu_freq().max:.2f} MHz\")\n",
    "\n",
    "# Check RAM\n",
    "print(f\"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ecbfa",
   "metadata": {},
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from read-only input\n",
    "original_dataset = load_from_disk(\"/kaggle/input/merged/tokenized_merged_wo_emojis\")\n",
    "\n",
    "working_dir = \"/kaggle/working/merged/tokenized_merged_wo_emojis\"\n",
    "# Save a copy to a writable location\n",
    "original_dataset.save_to_disk(working_dir)\n",
    "\n",
    "# Load the writable copy\n",
    "tokenized_dataset = load_from_disk(working_dir, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a4559",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    logits, labels = pred.predictions, pred.label_ids\n",
    "    \n",
    "    # Optional sanity check: make sure logits are not probabilities\n",
    "    if logits.shape[1] == 2:  # Binary classification logits\n",
    "        probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected logits shape: make sure model outputs raw logits with 2 classes.\")\n",
    "    \n",
    "    preds = (probs > 0.65).astype(int)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(labels, preds, average=None, zero_division=0)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "\n",
    "    wandb.log({\n",
    "        \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "            probs=None,\n",
    "            y_true=labels,\n",
    "            preds=preds,\n",
    "            class_names=[\"Non-Hate\", \"Hate\"]\n",
    "        ),\n",
    "        \"threshold_used\": 0.65  # <-- Log the threshold too!\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'matthews_corrcoef': mcc,\n",
    "        'precision_class_0': precision_per_class[0],\n",
    "        'precision_class_1': precision_per_class[1],\n",
    "        'recall_class_0': recall_per_class[0],\n",
    "        'recall_class_1': recall_per_class[1],\n",
    "        'f1_class_0': f1_per_class[0],\n",
    "        'f1_class_1': f1_per_class[1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febebcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ðŸ“¦ Dataset & Batching Config\n",
    "# ============================\n",
    "data_config = {\n",
    "    \"per_device_train_batch_size\": 512,\n",
    "    \"per_device_eval_batch_size\": 256,\n",
    "    \"dataloader_pin_memory\": False,\n",
    "    \"label_names\": [\"labels\"]\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# âš™ï¸ Training Runtime Setup\n",
    "# ========================\n",
    "runtime_config = {\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_checkpointing\": True\n",
    "}\n",
    "\n",
    "# =============================\n",
    "# ðŸ”§ Optimization Configuration\n",
    "# =============================\n",
    "optimizer_config = {\n",
    "    \"optim\": \"adamw_torch_fused\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"learning_rate\": 2e-3,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"weight_decay\": 0.01\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# ðŸ“Š Logging & Saving Strategy\n",
    "# ==============================\n",
    "logging_config = {\n",
    "    \"report_to\": \"wandb\",\n",
    "    \"logging_steps\": 200,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 200,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 200,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"matthews_corrcoef\",\n",
    "    \"greater_is_better\": True\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# ðŸ§¬ Final Training Configuration\n",
    "# ===============================\n",
    "training_kwargs = {\n",
    "    **data_config,\n",
    "    **runtime_config,\n",
    "    **optimizer_config,\n",
    "    **logging_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f6f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vinai/bertweet-base'\n",
    "\n",
    "model_kwargs = {\n",
    "    \"num_labels\": 2,\n",
    "    \"device_map\": \"cuda\",\n",
    "    \"low_cpu_mem_usage\": True,\n",
    "    # \"quantization_config\": bnb_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init W&B run\n",
    "wandb.init(project=\"bertweet-lora-bayes-v2\", name=\"final_run_mcc_0.65_v3\")\n",
    "\n",
    "# Best config\n",
    "best_config = {\n",
    "    \"r\": 16,\n",
    "    \"alpha\": 12,\n",
    "    \"target_modules\": [\"query\", \"key\", \"value\", \"attention.output.dense\"]\n",
    "}\n",
    "\n",
    "# Setup LoRA\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=best_config[\"r\"],\n",
    "    lora_alpha=best_config[\"alpha\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"all\",\n",
    "    target_modules=best_config[\"target_modules\"],\n",
    "    modules_to_save=[\"classifier\"]\n",
    ")\n",
    "\n",
    "# Load and prepare model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, **model_kwargs)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.config.id2label = {0: \"Non-Hate\", 1: \"Hate\"}\n",
    "model.config.label2id = {\"Non-Hate\": 0, \"Hate\": 1}\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(**training_kwargs)\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train and Evaluate\n",
    "trainer.train()\n",
    "\n",
    "model.save_model(\"./final_model\")\n",
    "artifact = wandb.Artifact(\"final_model\", type=\"model\")\n",
    "artifact.add_dir(\"./final_model\")\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# Post-training test evaluation (at threshold 0.65)\n",
    "test_preds = trainer.predict(tokenized_dataset[\"test\"])\n",
    "test_probs = torch.softmax(torch.tensor(test_preds.predictions), dim=1)[:, 1].numpy()\n",
    "test_labels = test_preds.label_ids\n",
    "final_preds = (test_probs > 0.65).astype(int)\n",
    "\n",
    "final_mcc = matthews_corrcoef(test_labels, final_preds)\n",
    "final_acc = accuracy_score(test_labels, final_preds)\n",
    "\n",
    "wandb.log({\n",
    "    \"test/mcc_thresh_0.65\": final_mcc,\n",
    "    \"test/accuracy_thresh_0.65\": final_acc\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0815a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d465934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume model is a LoRA-wrapped PEFT model\n",
    "merged_model = model.merge_and_unload()  # Merges LoRA into base\n",
    "# print(merged_model)\n",
    "\n",
    "# # Then save the merged model\n",
    "merged_model.save_pretrained(\"final_full_model\")\n",
    "# tokenizer.save_pretrained(\"final_full_model\")\n",
    "\n",
    "artifact = wandb.Artifact(\"final_model\", type=\"model\")\n",
    "artifact.add_dir(\"./final_full_model\")\n",
    "wandb.log_artifact(artifact)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "afa00e08-347e-4731-a6b4-fbc28bcfdd6a",
    "_uuid": "6e591cf0-1161-40ff-889a-b73b1bbcf5df",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:43.899265Z",
     "iopub.status.busy": "2025-04-22T14:43:43.897978Z",
     "iopub.status.idle": "2025-04-22T14:43:43.903699Z",
     "shell.execute_reply": "2025-04-22T14:43:43.902855Z",
     "shell.execute_reply.started": "2025-04-22T14:43:43.899237Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "import cpuinfo\n",
    "\n",
    "# Experiment Tracking\n",
    "import wandb\n",
    "\n",
    "# Sklearn Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support, \n",
    "    matthews_corrcoef, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Hugging Face Datasets\n",
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# PEFT (Parameter Efficient Fine-Tuning)\n",
    "from peft import (\n",
    "    LoraConfig, \n",
    "    get_peft_model, \n",
    "    TaskType,\n",
    "    PeftModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20f5bf5e-e946-4505-907e-e359d51091a0",
    "_uuid": "c8ff3eb4-ea01-4533-a1ff-9c8225ebd131",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:45.991829Z",
     "iopub.status.busy": "2025-04-22T14:43:45.991539Z",
     "iopub.status.idle": "2025-04-22T14:43:46.129262Z",
     "shell.execute_reply": "2025-04-22T14:43:46.128364Z",
     "shell.execute_reply.started": "2025-04-22T14:43:45.991805Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"wandb_api\")\n",
    "    wandb.login(key=api_key)\n",
    "    anony = None\n",
    "except:\n",
    "    anony = \"must\"\n",
    "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "428ea3a1-c5d9-4e01-9d13-6401f1c2340d",
    "_uuid": "ed4ad27f-9f68-4c62-8dca-b575f329cf4b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:43.905161Z",
     "iopub.status.busy": "2025-04-22T14:43:43.904930Z",
     "iopub.status.idle": "2025-04-22T14:43:43.919124Z",
     "shell.execute_reply": "2025-04-22T14:43:43.918366Z",
     "shell.execute_reply.started": "2025-04-22T14:43:43.905146Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import multiprocessing as mp\n",
    "# mp.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "214b6094-179d-4cb4-8157-aea1b1a52d58",
    "_uuid": "71160d77-eba6-4c2f-aaea-ce9711581670",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# GPU & CPU Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b9ad9e40-2602-4f97-98a5-f486e082ee8d",
    "_uuid": "6611d2f1-05a9-4f62-90c5-08f3de1d931d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:43.920063Z",
     "iopub.status.busy": "2025-04-22T14:43:43.919849Z",
     "iopub.status.idle": "2025-04-22T14:43:43.934613Z",
     "shell.execute_reply": "2025-04-22T14:43:43.934026Z",
     "shell.execute_reply.started": "2025-04-22T14:43:43.920047Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu124\n",
      "CUDA available: True\n",
      "GPU name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb065385-059d-4c57-9f95-6ca9b358df4a",
    "_uuid": "22f3cbf5-ff52-46ac-a7c1-7ff9932afbd9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:43.936541Z",
     "iopub.status.busy": "2025-04-22T14:43:43.936316Z",
     "iopub.status.idle": "2025-04-22T14:43:45.132128Z",
     "shell.execute_reply": "2025-04-22T14:43:45.131231Z",
     "shell.execute_reply.started": "2025-04-22T14:43:43.936526Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "Cores: 2 Physical / 4 Logical\n",
      "Max Frequency: 0.00 MHz\n",
      "RAM: 31.4 GB\n"
     ]
    }
   ],
   "source": [
    "# Get CPU model and cores\n",
    "cpu_info = cpuinfo.get_cpu_info()\n",
    "print(f\"CPU Model: {cpu_info['brand_raw']}\")\n",
    "print(f\"Cores: {psutil.cpu_count(logical=False)} Physical / {psutil.cpu_count(logical=True)} Logical\")\n",
    "\n",
    "# Get clock speed\n",
    "print(f\"Max Frequency: {psutil.cpu_freq().max:.2f} MHz\")\n",
    "\n",
    "# Check RAM\n",
    "print(f\"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b9810101-9173-41bb-9d68-a0cfe571d8c1",
    "_uuid": "68b3ff1c-e244-444b-8786-5db91878baeb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e873cee5-b3d3-4d24-91b9-ddf238235f77",
    "_uuid": "8a5bc662-4daf-4270-9269-d539196bebce",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:45.133263Z",
     "iopub.status.busy": "2025-04-22T14:43:45.132961Z",
     "iopub.status.idle": "2025-04-22T14:43:45.970856Z",
     "shell.execute_reply": "2025-04-22T14:43:45.970286Z",
     "shell.execute_reply.started": "2025-04-22T14:43:45.133237Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a78854018140dea2a39f39bf30bbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/494172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0128860234f64fbf8ce9f984ed0b7e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e50596b02f4d12966c19abf61b8a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load from read-only input\n",
    "original_dataset = load_from_disk(\"/kaggle/input/merged/tokenized_merged_wo_emojis\")\n",
    "\n",
    "working_dir = \"/kaggle/working/merged/tokenized_merged_wo_emojis\"\n",
    "# Save a copy to a writable location\n",
    "original_dataset.save_to_disk(working_dir)\n",
    "\n",
    "# Load the writable copy\n",
    "tokenized_dataset = load_from_disk(working_dir, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "1e2b2663-bbab-47e7-96d4-570da1608d0f",
    "_uuid": "005f5f66-83c9-4710-8e0e-d7b08cd261b3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:45.972319Z",
     "iopub.status.busy": "2025-04-22T14:43:45.972057Z",
     "iopub.status.idle": "2025-04-22T14:43:45.977099Z",
     "shell.execute_reply": "2025-04-22T14:43:45.976472Z",
     "shell.execute_reply.started": "2025-04-22T14:43:45.972294Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "c9f911cb-73eb-4717-9811-180418053cf0",
    "_uuid": "5e2e8dd0-9754-4c04-b2db-06dfe728c754",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:45.978355Z",
     "iopub.status.busy": "2025-04-22T14:43:45.977864Z",
     "iopub.status.idle": "2025-04-22T14:43:45.990861Z",
     "shell.execute_reply": "2025-04-22T14:43:45.990128Z",
     "shell.execute_reply.started": "2025-04-22T14:43:45.978337Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2fd2aa03-911a-49b5-b4f6-44374a44c7f8",
    "_uuid": "d624044b-c8d7-4559-8999-c5c5ff6d931a",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Sweep Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "44b76ad9-8c92-45e1-8b75-6adfa181b029",
    "_uuid": "2ae7d163-040c-4e3a-9274-ea436aad245b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:46.132125Z",
     "iopub.status.busy": "2025-04-22T14:43:46.131395Z",
     "iopub.status.idle": "2025-04-22T14:43:46.135748Z",
     "shell.execute_reply": "2025-04-22T14:43:46.135055Z",
     "shell.execute_reply.started": "2025-04-22T14:43:46.132098Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'name': 'Fourth Sweep',\n",
    "    'method': 'bayes',  # Bayesian optimization\n",
    "    'metric': {\n",
    "        'name': 'test_matthews_corrcoef',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'early_terminate': {\n",
    "        'type': 'hyperband',  # Revert to original hyperband termination\n",
    "        'min_iter': 3         # Keep original minimum iterations\n",
    "    },\n",
    "    'parameters': {\n",
    "        'target_modules': {\n",
    "            'values': [\n",
    "                [\"query\", \"key\"],\n",
    "                [\"query\", \"key\", \"value\"],\n",
    "                [\"query\", \"key\", \"value\", \"attention.output.dense\"]\n",
    "            ]\n",
    "        },\n",
    "        'lora_r': {\n",
    "            'values': [16, 32, 64]\n",
    "        },\n",
    "        'lora_alpha': {\n",
    "            'values': [4, 8, 12, 16, 24, 32, 48]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8e1dc2b0-6d2a-43c6-be85-12b45ffe4d0f",
    "_uuid": "e2b6a6c8-ea60-48c0-a124-819ccb7ef969",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:46.137086Z",
     "iopub.status.busy": "2025-04-22T14:43:46.136821Z",
     "iopub.status.idle": "2025-04-22T14:43:46.148787Z",
     "shell.execute_reply": "2025-04-22T14:43:46.148132Z",
     "shell.execute_reply.started": "2025-04-22T14:43:46.137058Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"bertweet-lora-bayes-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:46.149898Z",
     "iopub.status.busy": "2025-04-22T14:43:46.149638Z",
     "iopub.status.idle": "2025-04-22T14:43:46.162114Z",
     "shell.execute_reply": "2025-04-22T14:43:46.161578Z",
     "shell.execute_reply.started": "2025-04-22T14:43:46.149878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    logits, labels = pred.predictions, pred.label_ids\n",
    "    \n",
    "    # Optional sanity check: make sure logits are not probabilities\n",
    "    if logits.shape[1] == 2:  # Binary classification logits\n",
    "        probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected logits shape: make sure model outputs raw logits with 2 classes.\")\n",
    "    \n",
    "    preds = (probs > 0.65).astype(int)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(labels, preds, average=None, zero_division=0)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "\n",
    "    wandb.log({\n",
    "        \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "            probs=None,\n",
    "            y_true=labels,\n",
    "            preds=preds,\n",
    "            class_names=[\"Non-Hate\", \"Hate\"]\n",
    "        ),\n",
    "        \"threshold_used\": 0.65  # <-- Log the threshold too!\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'matthews_corrcoef': mcc,\n",
    "        'precision_class_0': precision_per_class[0],\n",
    "        'precision_class_1': precision_per_class[1],\n",
    "        'recall_class_0': recall_per_class[0],\n",
    "        'recall_class_1': recall_per_class[1],\n",
    "        'f1_class_0': f1_per_class[0],\n",
    "        'f1_class_1': f1_per_class[1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "e84f9333-406d-4b1d-afcf-02a8742fa409",
    "_uuid": "c84ba127-e8e2-459f-9818-6e222603b658",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:46.180378Z",
     "iopub.status.busy": "2025-04-22T14:43:46.179823Z",
     "iopub.status.idle": "2025-04-22T14:43:46.195602Z",
     "shell.execute_reply": "2025-04-22T14:43:46.195027Z",
     "shell.execute_reply.started": "2025-04-22T14:43:46.180336Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ðŸ“¦ Dataset & Batching Config\n",
    "# ============================\n",
    "data_config = {\n",
    "    \"per_device_train_batch_size\": 512,\n",
    "    \"per_device_eval_batch_size\": 256,\n",
    "    \"dataloader_pin_memory\": False,\n",
    "    \"label_names\": [\"labels\"]\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# âš™ï¸ Training Runtime Setup\n",
    "# ========================\n",
    "runtime_config = {\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"fp16\": True,\n",
    "    \"gradient_checkpointing\": True\n",
    "}\n",
    "\n",
    "# =============================\n",
    "# ðŸ”§ Optimization Configuration\n",
    "# =============================\n",
    "optimizer_config = {\n",
    "    \"optim\": \"adamw_torch_fused\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"learning_rate\": 2e-3,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"weight_decay\": 0.01\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# ðŸ“Š Logging & Saving Strategy\n",
    "# ==============================\n",
    "logging_config = {\n",
    "    \"report_to\": \"wandb\",\n",
    "    \"logging_steps\": 200,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 200,\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 200,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"matthews_corrcoef\",\n",
    "    \"greater_is_better\": True\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# ðŸ§¬ Final Training Configuration\n",
    "# ===============================\n",
    "training_kwargs = {\n",
    "    **data_config,\n",
    "    **runtime_config,\n",
    "    **optimizer_config,\n",
    "    **logging_config\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a17df2e4-e504-4698-a2e6-e66e89ed5f3e",
    "_uuid": "e4a35827-f7e4-44ab-9402-ae5350e9d1b2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "6c887e8a-d7bb-424e-976e-8e5cf52fdf31",
    "_uuid": "bcada726-64c8-472c-8d49-47e38fdc4a26",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:46.211681Z",
     "iopub.status.busy": "2025-04-22T14:43:46.211308Z",
     "iopub.status.idle": "2025-04-22T14:43:46.220790Z",
     "shell.execute_reply": "2025-04-22T14:43:46.220226Z",
     "shell.execute_reply.started": "2025-04-22T14:43:46.211659Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = 'vinai/bertweet-base'\n",
    "\n",
    "model_kwargs = {\n",
    "    \"num_labels\": 2,\n",
    "    \"device_map\": \"cuda\",\n",
    "    \"low_cpu_mem_usage\": True,\n",
    "    # \"quantization_config\": bnb_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e5d993e-a91c-409f-90f8-a28d08affe20",
    "_uuid": "d0329d21-f452-4c77-9007-92376475758b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:46.222047Z",
     "iopub.status.busy": "2025-04-22T14:43:46.221773Z",
     "iopub.status.idle": "2025-04-22T14:43:46.235357Z",
     "shell.execute_reply": "2025-04-22T14:43:46.234610Z",
     "shell.execute_reply.started": "2025-04-22T14:43:46.222025Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    # Initialize W&B run\n",
    "    with wandb.init(config=config): \n",
    "        # Get hyperparameters from W&B\n",
    "        config = wandb.config\n",
    "        \n",
    "        # Load model with all kwargs\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            **model_kwargs\n",
    "        )\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "        \n",
    "        # Setup LoRA\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            r=config.lora_r,\n",
    "            lora_alpha= config.lora_alpha,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"all\",\n",
    "            target_modules= config.target_modules,\n",
    "            modules_to_save=[\"classifier\"]\n",
    "        )\n",
    "                \n",
    "        model = get_peft_model(model, peft_config)\n",
    "\n",
    "        # model = torch.compile(model)\n",
    "                \n",
    "        # Fix label mappings\n",
    "        model.config.id2label = {0: \"Non-Hate\", 1: \"Hate\"}\n",
    "        model.config.label2id = {\"Non-Hate\": 0, \"Hate\": 1}\n",
    "        \n",
    "        # Calculate trainable parameters\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_ratio = 100 * trainable_params / total_params\n",
    "        \n",
    "        model.print_trainable_parameters()\n",
    "\n",
    "    \n",
    "        training_args = TrainingArguments(\n",
    "        **training_kwargs\n",
    "    )\n",
    "    \n",
    "        # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "            model=model, args=training_args,\n",
    "            train_dataset=tokenized_dataset[\"train\"],\n",
    "            eval_dataset=tokenized_dataset[\"validation\"],\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "    \n",
    "    # Train and evaluate\n",
    "    trainer.train()\n",
    "    test_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
    "\n",
    "    results_to_log = {\n",
    "        # Training metrics\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"trainable_ratio\": trainable_ratio,\n",
    "        \n",
    "        # Evaluation metrics (prefixed for clarity)\n",
    "        \"test_matthews_corrcoef\": test_results[\"eval_matthews_corrcoef\"],\n",
    "        \"test/accuracy\": test_results[\"eval_accuracy\"],\n",
    "        \"test/f1\": test_results[\"eval_f1\"],\n",
    "        \n",
    "        # Hyperparameters\n",
    "        \"hp/lora_r\": config.lora_r,\n",
    "        \"hp/lora_alpha\": config.lora_alpha,\n",
    "        \"hp/lora_ratio\": config.lora_alpha/config.lora_r,\n",
    "    }\n",
    "    \n",
    "    wandb.log(results_to_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "646f6b10-48a6-42de-8163-8ba94df7ca83",
    "_uuid": "6e92aca2-6345-4d71-8a50-20eb94e9c6e6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:46.236366Z",
     "iopub.status.busy": "2025-04-22T14:43:46.236192Z",
     "iopub.status.idle": "2025-04-22T14:43:46.249420Z",
     "shell.execute_reply": "2025-04-22T14:43:46.248756Z",
     "shell.execute_reply.started": "2025-04-22T14:43:46.236352Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def run_agent(gpu_id):\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "#     wandb.agent(sweep_id, function=train, count=16)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     processes = []\n",
    "#     for gpu in [0, 1]:\n",
    "#         p = mp.Process(target=run_agent, args=(gpu,))\n",
    "#         p.start()\n",
    "#         processes.append(p)\n",
    "\n",
    "#     for p in processes:\n",
    "#         p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e46468a-616b-4785-a3f5-80392dd0baec",
    "_uuid": "3d64f5b0-b044-44a2-a363-fd864ada871f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-22T14:43:46.250414Z",
     "iopub.status.busy": "2025-04-22T14:43:46.250151Z",
     "iopub.status.idle": "2025-04-22T14:43:46.261381Z",
     "shell.execute_reply": "2025-04-22T14:43:46.260833Z",
     "shell.execute_reply.started": "2025-04-22T14:43:46.250391Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run the sweep\n",
    "wandb.agent(sweep_id, function=train, count=24)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7033430,
     "sourceId": 11254644,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7128090,
     "sourceId": 11516094,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
